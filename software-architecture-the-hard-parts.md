[Back](/)

# Software Architecture: The Hard Parts: Modern Trade-Off Analyses for Distributed Architectures
Neal Ford, Mark Richards, Pramod Sadalage, Zhamak Dehghani (2021)

---

## TL;DR
- Don‚Äôt compare all pros/cons: narrow down the list depending on your context, goals
- Try to become the objective arbiter of trade-offs
- Breadth of knowledge is more important than depth
- Fitness functions: ‚Äúarchitecture as code‚Äù to measure and regression test architectural designs
    - Keep services roughly the same size
    - Flag too many dependencies
    - Flag disallowed dependencies
    - Flag new components for review
- Service integrators/disingetrators: size, cohesion, volatility (rates of change), scalability/throughput, fault tolerance, security, extensibility, database transactions, shared data, shared code
- Data ownership: start with who writes to the table; failing that,
    - If many writers, create a service that writes to the table
    - Otherwise, split the table
    - Or make a choice‚Äîassign it to a service
    - Or combine the services
- Distributed data access
    - Service A asks B for the data
    - Replicate column between databases
    - Replicate data via a distributed cache (read-only)
- Choreography and complex workflows that need to recover from errors don‚Äôt mix well

## Podcast interview with Neal Ford
[#120 - Software Architecture: From Fundamentals to the Hard Parts - Neal Ford](https://podcasts.apple.com/us/podcast/tech-lead-journal/id1523421550?i=1000599335450), Tech Lead Journal (Henry Suryawirawan)

Architecture:

- You can‚Äôt search for the answers online
- There are always trade-offs; it‚Äôs about finding the least worse option, based on business goals/priorities
- _Why_ is more important than _how_; document trade-offs

Skills:

- Breadth is more important than depth
  - Knowing about 5 different ways to solve a problem ‚úÖ
  - Knowing 1 specific solution really well ‚ùå
- Conflict resolution

> Your database schema is one of your most intense implementation details of your architecture, and the more you let implementation details leak out into your architecture, the more brittle your architecture becomes. Meaning you make one change somewhere and it breaks a whole bunch of stuff.

## DDD
- **Domain**: broadest concept; your application or business may model a single domain
- **Subdomain**: part of a domain; examples might be: payments, customer management. Types:
    - **Core**: what makes your company unique, or its competitive advantage; invest the most here (deep domain expertise, frequent evolution or highly maintainable, high quality)
    - **Supporting**: necessary but not differentiator, not strategic (good enough, consider outsourcing or using off-the-shelf)
    - **Generic**: commoditised; use existing solutions (e.g., auth, logging, billing, CRM‚Ä¶)
- **Bounded context**: same language applies consistently; might cover a single subdomain, part of a subdomain or several subdomains (our src/domains/ folder is for bounded contexts). They contain:
    - **Entities**: have a distinct identity over time, even if their data changes (e.g., a customer)
    - **Value objects**: no identity, just a set of attributes; typically immutable‚Äîyou replace, not modify (e.g., address: two identical addresses are treated as the same thing)
    - **Aggregates**: groups of entities and value objects; they have a root entity (‚Äúaggregate root‚Äù). E.g., an order (root) with items (child entities)
    - **Services**: operations that don‚Äôt naturally belong to an entity or value object, but they operate on entities and value objects
        - In DDD, domain services aren‚Äôt exactly the API layer: domain services are ‚Äúpure‚Äù and have a thin application layer on top of them where the HTTP, auth, etc concerns live
        - Confusingly, ‚Äúdomain services‚Äù don‚Äôt mean ‚Äúservices for the whole domain‚Äù‚Äîdomain services live inside a bounded context
    - **Repositories**: abstractions for accessing aggregates (e.g., `OrderRepository.save()` or `findById()`). Typically one repository per aggregate root

## Notes
#### Chapter 1. What happens when there are no ‚Äúbest practices‚Äù?
> Change is also difficult and risky in this large monolith. Whenever a change is made, it usually takes too long and something else usually breaks‚Ä¶ resulting in all application functionality not being available anywhere from five minutes to two hours while the problem is identified and the application is restarted. 17

ü§î We don‚Äôt usually break other things, because of tests? Or failover? Or‚Ä¶?

Architectural decision records should provide justifications, describe trade-offs and list alternatives.

### Part 1. Pulling things apart
#### Chapter 2. Discerning coupling in software architecture

<!--
Definitions:

- **Static coupling**. Operational dependencies (database, operating system, frameworks, packages, Docker, event brokers‚Ä¶)
    - A service can in theory run with just the static coupling, but it likely needs the dynamic coupling at runtime to do anything useful
    - ‚ÄúIs this dependent of the architecture necessary to bootstrap this service?‚Äù 33
    - ‚Äú‚Ä¶ does not consider other quanta whose only coupling point is workflow communication with this quantum.‚Äù 401
- **Dynamic coupling**. How services communicate at runtime‚Äîcommunication dependencies (sync/async‚Ä¶)
    - Imagine two services with different scaling needs. Calls can‚Äôt be sync because one will be hung up waiting for the other, and the other may be swamped with calls
    - More on this later: sync/async communication, atomic/eventual consistency, orchestration/choreography
- **Architecture quantum**. Independently deployable; high functional cohesion, high static coupling, synchronous dynamic coupling
   - A microservice in a workflow
   - A bounded context in DDD
-->

Topologies of one (because of the static coupling of a single database or front-end, even if multiple services are deployed),

- **Layered monolith**. Horizontal technical layers; e.g., MVC
- **Modular monolith**. Vertical functional layers
- **Microkernel**. Large core surrounded by plug-in components
- **Service-based**. Like microservices, but a shared database ‚Äúbecause the architects didn‚Äôt see the value in separation (or saw too many negative trade-offs).‚Äù 32
    - You can focus on the domains, not the database
    - ‚ÄúWhen migrating monolithic applications to microservices, consider moving to a service-based application first as a stepping stone to microservices.‚Äù 72
- **Microservices** with a tightly coupled _single_ front-end (reasoning: the UI won‚Äôt work without the services, and because they serve the same UI they probably won‚Äôt have different scaling requirements)

ü§î Because of Automat etc, aren‚Äôt we service-based, with a large shared library?

Topologies of many:

- **Microservices** with micro front-ends: each service has its own static dependencies, including its own database

#### Chapter 3. Architectural modularity
Elasticity: speed with which scale can change. Monolithic applications have a large MTTS.

> Elasticity relies on services having a very small mean time to startup (MTTS), which is achieved architecturally by having very small, fine-grained services. 57

| Architecture  | Scalability | Elasticity | Notes                         |
|---------------|------------:|-----------:|-------------------------------|
| Monolithic    |         ‚≠êÔ∏è |          ‚≠êÔ∏è | Application-level scalability |
| Service-based |     ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è‚≠êÔ∏è | Domain-level scalability      |
| Microservices | ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |  ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è | Function-level scalability    |

ü§î Many other aspects are missing here: maintainability, debuggability, etc

#### Chapter 4. Architectural decomposition
Tactical forking: instead of extracting functionality to create domains, copy the entire application to each domain, then delete what‚Äôs not needed. It makes more sense in apps that are very badly structured. But the drawbacks are problematic: without extra effort you‚Äôll end up with duplicate, inconsistent and leftover code.

ü§î It doesn‚Äôt seem like this as a serious option

#### Chapter 5. Component-based decomposition patterns
‚ÄúComponent-based decomposition‚Ä¶ is a highly effective technique for breaking apart a monolithic application when the codebase is somewhat structured and grouped by namespaces (or directories).‚Äù 82

‚ÄúInitially, these patterns are used together in sequence when moving a monolithic application to a distributed one, and then individually as maintenance is applied to the monolithic application during migration.‚Äù 82

Architectural fitness functions are set up to make sure we don‚Äôt deviate from the plan later on. Some of these are used for planning, or even evaluating whether the move is feasible:

- **Identify and size components**
    - List the number of statements per domain (or lines of code) and consider breaking up large domains into subdomains. Show per cent size. We‚Äôre looking for generally same-sized domains
    - Fitness function: flag too big components
- **Gather common domain components**
    - Differentiate between domain functionality (formatting, validation‚Ä¶) and infrastructure functionality which is common to all processes (logging, security‚Ä¶)
    - Fitness function: flag duplicate code
- **Flatten components**
    - Within functional grouping, everything should be a leaf, even shared code
    - Fitness function: no shared code in root directories
- **Determine component dependencies**
    - Visualise the dependencies between modules to understand how complex the project will be (ignore shared infrastructure modules)
    - Fitness function: flag too many dependencies (incoming, outgoing, or both)
    - Fitness function: disallow dependencies between certain modules
- **Create component domains**
    - They propose this structure: domain/subdomain/component
    - Fitness function: flag new components
- **Create domain services**
    - Once all domains are working and established, move them out to separate services, one at a time (start service-oriented‚Äîkeep the shared database)

#### Chapter 6. Pulling apart operational data
Consider splitting the database when:

- Services are competing for resources (connections, throughput)
- You don‚Äôt want one database outage to bring everything down (fault tolerance)
- You don‚Äôt want to tie schema changes to multiple services (lockstep deployments)
- You want different database types

| Criteria            | Relational | Key-Value | Document | Column    | Graph  | Distributed SQL | Cloud Native | Time-Series |
|---------------------|-----------:|----------:|---------:|----------:|-------:|----------------:|-------------:|------------:|
| Ease of learning    |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |    ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |      ‚≠êÔ∏è‚≠êÔ∏è |     ‚≠êÔ∏è |          ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |         ‚≠êÔ∏è‚≠êÔ∏è |          ‚≠êÔ∏è |
| Ease of modeling    |     ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è |          ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |         ‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è‚≠êÔ∏è |
| Scalability         |       ‚≠êÔ∏è‚≠êÔ∏è |  ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |     ‚≠êÔ∏è‚≠êÔ∏è |  ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è | ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |          ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |     ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |    ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |
| Partition tolerance |         ‚≠êÔ∏è |  ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |  ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è | ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |          ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |       ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è‚≠êÔ∏è |
| Consistency         | ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |      ‚≠êÔ∏è‚≠êÔ∏è |     ‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è | ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |            ‚≠êÔ∏è‚≠êÔ∏è |       ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |      ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |
| Maturity            |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |    ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è |      ‚≠êÔ∏è‚≠êÔ∏è |   ‚≠êÔ∏è‚≠êÔ∏è |            ‚≠êÔ∏è‚≠êÔ∏è |         ‚≠êÔ∏è‚≠êÔ∏è |        ‚≠êÔ∏è‚≠êÔ∏è |
| Read/write priority |   Flexible |     80/20 |    80/20 |     20/80 |  80/20 |        Flexible |        80/20 |       60/40 |

‚ö†Ô∏è I think there‚Äôs a lot missing that could be important, depending on your use case: schema-less, aggregate queries, text search (where‚Äôs Elastic?), memory databases‚Ä¶ Also, within each category, different products can have different characteristics.

| Database type   | Products                                   |
|-----------------|--------------------------------------------|
| Relational      | PostgreSQL, MySQL, Oracle, SQL Server      |
| Key-value       | Riak KV, Amazon DynamoDB, Redis, Memcached |
| Dcoument        | MongoDB, Couchbase, Amazon DocumentDB      |
| Column          | Cassandra, Scylla, Amazon SimpleDB         |
| Graph           | Neo4j, Infinite Graph, Tiger Graph         |
| Distributed SQL | VoltDB, ClustrixDB, SimpleStore            |
| Cloud native    | Snowflake, Datomic, Amazon Redshift        |
| Time-series     | InfluxDB, kdb+, Amazon Timestream          |

üìò [NoSQL Distilled: A Brief Guide to the Emerging World of Polyglot Persistence](https://www.amazon.com/NoSQL-Distilled-Emerging-Polyglot-Persistence/dp/0321826620) (Pramod Sadalage, Martin Fowler).

#### Chapter 7. Service granularity
> ‚Äú‚Ä¶ Let‚Äôs take our customer notification service as an example. We can notify our customers through SMS, email, and we even send out postal letters. So tell me everyone, one service or three services.‚Äù
>
> ‚ÄúThree,‚Äù immediately answered Taylor. ‚ÄúEach notification method is its own thing. That‚Äôs what microservices is all about.‚Äù
>
> ‚ÄúOne,‚Äù answered Addison. ‚ÄúNotification itself is clearly a single responsibility.‚Äù
>
> ‚ÄúI‚Äôm not sure,‚Äù answered Austen. ‚ÄúI can see it both ways. Should we just toss a coin?‚Äù
>
> ‚ÄúThis is exactly why we need help,‚Äù sighed Addison.
>
> ‚ÄúThe key to getting service granularity right,‚Äù said Logan, ‚Äúis to remove opinion and gut feeling, and use granularity disintegrators and integrators to objectively analyse the trade-offs and form solid justifications for whether or not to break apart a service.‚Äù 186

Disintegrators:

- Is the service doing too many unrelated things? Is the service too big?
    - Example: the customer service is doing unrelated things: profile, preferences and comments
    - Similar reasoning: the code doesn‚Äôt fit easily into one person‚Äôs head
- Different rates of change
    - Example: the weekly changes made to one subdomain cause tests to the whole domain
    - These things might not go together (if they were cohesive they would change at the same time)
- Different performance demands
    - Example: notification methods have different scaling profiles: SMS 200,000/minute, email 500/minute, letters 1/minute
- Is a subdomain bringing all other subdomains down?
    - Example: out of memory errors in the email code brings down the other subdomains
- Do some parts need different security levels?
    - Example: a wallet service (with credit card information) vs a profile service (less secure)
- Is the service always expanding to add new contexts?
    - Example: a payments service that does credit cards, gift cards and PayPal, needs to accommodate ApplePay, rewards points, etc‚Äîconsider breaking each into its own service
    - Apply this driver once ‚Äúa pattern can be established or confirmation of continued extensibility can be confirmed.‚Äù 196

<!--
ü§î They argue an interesting perspective: out of the three notification methods, imagine email has to be extracted because of fault tolerance. Now, what do you call a service that notifies via SMS and letters? Because of naming, they break them up! I see it, but would struggle to justify it, and I would settle for a potentially less ideal set of names: EmailNotifications, and for everything else, Notifications

> This naming problem relates back to the service scope and function granularity disintegrator‚Äîif a service is too hard to name because it‚Äôs doing multiple things, then consider breaking apart the service. 194
-->

Integrators:

- Shared database objects: foreign keys, triggers, procedures, views or JOINs
- Are ACID transactions required?
    - Example: registering a new user across different services (profile and password) breaks ACID guarantees
- Do services need to talk to each other?
    - Example: when dependencies go down and consequently take down upstream services, the fault tolerance disintegrator doesn‚Äôt make sense
    - Example: getting data from a bunch of different services is slower than if they were one (this may not matter in batch processing)
- Do they need to share code?
    - Example: five services all use a shared library (not infrastructure or cross-cutting code) which changes, causing five separate deploys
    - As a rule of thumb, if the shared code is >40% of the collective codebase, consider integrating
    - The problem is exacerbated by frequent changes to the shared lib
- Does the data need to stay together?
    - Example: two different services that rely on each other‚Äôs data, maybe there are FKs: you have to choose between a lot of chatter between the services, or keeping them together

> ‚ÄúIn that case,‚Äù said Addison, ‚Äúlet‚Äôs analyse the trade-offs. Which is more important‚Äîisolating the assignment functionality for change control purposes, or combining assignment and routing into a single service for better performance, error-handling, and workflow control?‚Äù
>
> ‚ÄúWell,‚Äù said Taylor, ‚Äúwhen you put it that way, obviously the single service. But I still want to isolate the assignment code.‚Äù
>
> ‚ÄúOK,‚Äù said Addison, ‚Äúin that case, how about we make three distinct architectural components in the single service. We can delineate assignment, routing, and shared code with separate namespaces in the code. Would that help?‚Äù
>
> ‚ÄúYeah,‚Äù said Taylor, ‚Äúthat would work. OK, you both win. Let‚Äôs go with a single service then.‚Äù 211

> Parker noticed how Austen handled the meeting by facilitating the conversation rather than controlling it. This was an important lesson as an architect in identifying, understanding, and negotiating trade-offs. 215

<!--
ü§î How do you figure out trade-offs for other types of decisions? Is there a way to create a standard list that could work in many instances?

- Security
- Consistency
- Sync/async
- ‚Ä¶ ?
-->

### Part 2. Putting things back together
‚ÄúAttempting to divide a cohesive module would only result in increased coupling and decreased readability.‚Äù (Larry Constantine) 217

#### Chapter 8. Reuse patterns
- **Code replication**
    - Copy code into each service; after that, the code isn‚Äôt kept in sync
- **Shared library**
    - Keep the libraries small, to reduce upstream dependencies
    - Always version, for the same reason
    - Use a deprecation strategy
    - Don‚Äôt have upstream dependencies rely on the latest version‚Äîhot fixes may break those
    - Has compile-time checks
    - Use when the shared code changes infrequently
- **Shared service**
    - No compile-time checks
    - Versioning isn‚Äôt straightforward
    - Latency, scalability and fault tolerance concerns
    - Use when changes are frequent or in a polyglot environment
- **Sidecars and service mesh**
    - Sidecar is a helper process/container that runs along the main service (on Kubernetes, in the same pod)
    - You use it for infrastructure concerns like logging, networking, etc
    - Allows polyglot services
    - Service meshes insert sidecars automatically, declaratively
    - It‚Äôs a utility with a runtime, and runs next to each service (not centralised)

Code reuse isn‚Äôt always good. It creates brittleness: if reused code breaks, the change ‚Äúcould potentially impact every other domain, requiring coordination and testing to ensure that the change hasn‚Äôt ‚Äòrippled‚Äô throughout the architecture.‚Äù 243

> What architects failed to realise is that reuse has two important aspects; they got the first one correct: abstraction. The way architects and developers discover candidates for reuse is via abstraction. However, the second consideration is the one that determines utility and value: rate of change. 243

Reuse creates a dependency. If that shared component changes frequently, everyone who uses it feels it. So good reuse isn‚Äôt just about identifying common patterns (the abstraction bit), it‚Äôs about finding stable abstractions that don‚Äôt churn.

#### Chapter 9. Data ownership and distributed transactions
- **Single ownership scenario**. The service that writes to the table becomes the owner
    - Rule of thumb: if only one service writes to a table, that service owns the table
- **Common ownership**. Everyone or most services write to the table
    - Example: audits
    - Solution: create a service that‚Äôs called to write to the table
- **Joint ownership**. A few services write to the table
    - Solutions:
        - Split the table, sharing PKs. If distributed, CAP
        - Share table access, somehow making the table it‚Äôs own bounded context (‚Äúdata domain‚Äù)
        - Delegate technique: assign ownership to one service. Which? ‚ÄúThe first option, called primary domain priority, assigned table ownership to the service that most closely represents the primary domain of the data‚Äîin other words, the service that does most of the primary entity CRUD operations for the particular entity within the domain. The second option, called operational characteristics priority, assigned table ownership to the service needing higher operational architecture characteristics, such as performance, scalability, availability, and throughput.‚Äù 258
            - ‚ÄúRegardless of which service is assigned as the delegate (sole table owner), the delegate technique has some disadvantages, the biggest being service coupling and the need for interservice communication.‚Äù 260
        - Consolidate the services: turn them into a single service. Problems: increased testing scope, deployment risk, fault tolerance risk; can‚Äôt scale independently

üìò [Refactoring Databases](https://databaserefactoring.com/SplitTable.html) (Pramod Sadalage)

<!--
Eventual consistency patterns:

- Background synchronisation
- Orchestrated request-based (try doing everything synchronously)
- Event-based
-->

#### Chapter 10. Distributed data access
- **Interservice communication**. Service A asks service B for the data it needs; a network call
    - Pros: simple
    - Cons: slow (latency and throughput), no fault tolerance
- **Column schema replication**. Add service B data to the service A database, through queues, topics, event streaming‚Ä¶
    - Pros: performance, fault tolerance
    - Cons: consistency and ownership issues; complex data synchronisation
- **Replicated caching**. Replicated read-only cache replica on A (distributed cache)
    - Pros: fast access, scaleable, fault tolerance, data ownership preserved
    - Cons: limited data size, slower-changing data only
- **Data domain**. Discussed previously: A and B tables are contained in a separate data service which both can access; this is last resort
    - Cons: coupling

#### Chapter 11. Managing distributed workflows
‚ÄúOrchestration is useful when an architect must model a complex workflow that includes more than just the single ‚Äòhappy path,‚Äô but also alternate paths and error conditions.‚Äù 302

Centralisation makes error-handling and recovery easier, and state of the workflow is easily available. In contrast: potential bottleneck in terms of performance, single point of failure, limited scalability and coupling.

<!--
Semantic coupling: inherent in the requirements. ‚ÄúHowever clever an architect is, they cannot reduce the amount of semantic coupling, but their implementation choices may increase it.‚Äù 309
-->

Workflow state using choreography:

- **Front-controller pattern**. State is held by the first triggering service and each service reports as they complete
    - This is presented as a benefit: ‚ÄúCreates a pseudo-orchestrator within choreography‚Äù 312 ü§î
    - Cons: adds workflow state to a domain, increases communication overhead
- **Stateless choreography**. ‚Äú‚Ä¶ build a workflow that queries the state of each domain to determine the most up-to-date order status.‚Äù 313
- **Stamp coupling**. Pass state along with the message passed between services. This gives services more context but it doesn‚Äôt really provide a place to query job status

Choreography is more scalable (performance, parallelism), fault tolerant (choreographer is a single point of failure, but isn‚Äôt it the case that the more moving parts, the higher risk of failure? ü§î), more decoupled. In contrast: no central state management (and much harder to debug!), error-handling is more difficult (services must have more knowledge‚Ä¶ of each other, so coupling?), recoverability is more difficult (retries, etc).

> In the choreographed solution, removing the mediator forces higher levels of communication between services. This might be a perfectly suitable trade-off. For example, if an architect has a workflow that needs higher scale and typically has few error conditions, it might be worth trading the higher scale of choreography with the complexity of error handling. 315

> ‚Ä¶ as workflow complexity goes up, the need for an orchestrator rises proportionally‚Ä¶ 315

They lean on orchestration because trying to choreograph complex workflows can make things worse: you smear the mess around (similar to the way you smear related functionality across boundaries in a layered architecture).

> Ultimately, the sweet spot for choreography lies with workflows that need responsiveness and scalability, and either don‚Äôt have complex error scenarios or they are infrequent. 316

#### Chapter 12. Transactional sagas
I‚Äôve highlighted the patterns with the highest scores; they all use eventual consistency:

| Pattern/saga    | Communication | Consistency | Coordination | Coupling  | Complexity | Availability | Scale     |
|-----------------|---------------|-------------|--------------|-----------|------------|--------------|-----------|
| Epic            | Synchronous   | Atomic      | Orchestrated | Very high | Low        | Low          | Very low  |
| Phone Tag       | Synchronous   | Atomic      | Choreography | High      | High       | Low          | Low       |
| **Fairy Tale**  | Synchronous   | Eventual    | Orchestrated | High      | Very low   | Medium       | High      |
| **Time Travel** | Synchronous   | Eventual    | Choreography | Medium    | Low        | Medium       | High      |
| Fantasy Fiction | Async         | Atomic      | Orchestrated | High      | High       | Low          | Low       |
| Horror          | Async         | Atomic      | Choreography | Medium    | Very high  | Low          | Medium    |
| **Parallel**    | Async         | Eventual    | Orchestrated | Low       | Low        | High         | High      |
| **Anthology**   | Async         | Eventual    | Choreography | Very low  | High       | High         | Very high |

Complexity is the odd one out:

- With choreography (without a mediator), resolving errors becomes part of the responsibility of each service, so complexity increases
- Everything gets harder with async communication; the trade-off is higher performance and lower coupling

Simplifying a lot:

| In order to‚Ä¶         | Communication   | Consistency  | Coordination     | Pattern/saga       |
|----------------------|-----------------|--------------|------------------|--------------------|
| Reduce coupling      | **Async**       | **Eventual** | Choreography     | Anthology          |
| Reduce complexity    | **Synchronous** | **Eventual** | **Orchestrated** | Fairy Tale         |
| Improve availability | Async           | **Eventual** |                  | Parallel/Anthology |
| Improve scale        | Async           | **Eventual** | Choreography     | Anthology          |

Atomic consistency refers to distributed transactions. (They talk about compensating updates only, not multi-phase commits.)

> Distributed transactions are not something that can be simply ‚Äúdropped into‚Äù a system. They cannot be downloaded or purchases using some sort of framework or product like ACID transaction managers‚Äîthey must be designed, coded, and maintained by developers and architects. 356

Additional complications with compensating updates:

- Other services that may have already taken action before the compensating update is propagated, and there is no feasible way to undo that. These are called ‚Äúside effects.‚Äù It could be a service downstream of the one invoked by the orchestrator, or it may happen by another incoming call to the service invoked by the orchestrator. ‚ÄúThis scenario points to the importance of _isolation_ within a transaction, something that distributed transactions do not support.‚Äù 361
- A compensating update can fail!

> Alternatively, the mediator could insist that other services don‚Äôt accept calls during the course of a workflow, which guarantees a valid transaction but destroys performance and scalability. 363

Eventual consistency can be managed through state management. Consider a service that sends a survey at the end of a purchase. The orchestrator can mark this as _pending_ and retry later; failing that, ping someone to fix manually, or give up (some failures to send surveys may be tolerated).

#### Chapter 13. Contracts
‚ÄúMany architects like strict contracts because they model the identical semantic behaviour of internal method calls. However, strict contracts create brittleness in integration architecture‚Äîsomething to avoid.‚Äù 367

They‚Äôre saying you should be able to e.g., add fields to an object passed between services and not cause everyone to change.

More: ‚ÄúKeeping contracts at a ‚Äòneed to know‚Äô level strikes a balance between semantic coupling and necessary information without creating needles fragility in integration architecture.‚Äù 369

<!--
Loose is JSON, no schema.

Strict contacts provider guarantees (but tight coupling), are easier to verify at build time, better docs. A good use case is when ‚Äúinformation is highly semantically coupled and likely to change together‚Äù 379

Lose contacts are highly decoupled, easier to evolve, needs something like consumer-driven contracts. (An interesting use case is for apps that need approval from app stores‚Äîthey‚Äôre harder to change).

Stamp coupling = over-specify details that aren‚Äôt needed (return the ‚Äúfull object‚Äù even of consumer only needs some fields). ‚ÄúOver-specifying details in contracts is generally an anti-pattern‚Ä¶‚Äù 377

A valid use case is coordination in choreography (‚Äúthe semantic coupling must go somewhere‚Äù 378)
-->

#### Chapter 14. Managing analytical data
- Data warehouse (ETL)
- Data lake (ELT)
- Data mesh

<!--
Data warehouse pattern (~ETL)

- Centralised consolidation of data, isolation, but right coupling between operational database and transform logic
- Makes more sense in monolithic applications

Data lake pattern (~ELT)

- Centralised, isolated, less up-front transformation, better suited to distributed systems, but puts the burden on the analytics team to massage the data, dealing with PII becomes more problematic

Data mesh pattern

- Data becomes another product of each domain; data stays distributed but is available through self-serve mechanisms
- You would serve the data from a separate, tightly coupled, source/quantum (not your operational/transactional database)
- Each of these can then feed a common aggregate analytics service
- Suited to microservices, and when analytical data doesn‚Äôt have to stay in sync at all times
-->

#### Chapter 15. Building your own trade-off analysis 
- Focus on business drivers
- Cross-team collaboration
- Trade-off analyses
- Architecture decision records

1. Find the coupling points in the architecture: ‚Äúif someone changes X, will it possibly force Y to change?‚Äù 401
    - Static coupling
    - Dynamic coupling (communication, consistency and coordination)
2. Analyse the coupling points: ‚Äúmodel the possible combinations in a lightweight way.‚Äù 402
    - ‚ÄúThe goal of the analysis is to determine what forces the architect needs to study‚Äîin other words, which forces require trade-off analysis? For example, for our architecture quantum dynamic coupling analysis, we chose coupling, complexity, responsiveness/availability, and scale/elasticity as our primary trade-off concerns, in addition to analysing the three forces of communication, consistency, and coordination‚Ä¶‚Äù 402

Trade-off techniques:

- ‚ÄúIt‚Äôs important for architects to be sure they are comparing the same things rather than wildly different ones.‚Äù 404. E.g., don‚Äôt compare simple message queues to enterprise service buses
- Don‚Äôt compare all pros/cons, choose the right things to balance depending on your own context/needs
    - Having fewer options to consider will also make decisions easier
    - ‚ÄúFinding the correct narrow context for decisions allows architects to think about less, in many cases simplifying design.‚Äù 407
- Consider working through the problems iteratively, ‚Äúdiagramming sample architectural solutions to play qualitative ‚Äòwhat-if‚Äô games to see how architecture dimensions impact one another.‚Äù 407
    - This is easier when you combine it with the idea below: narrow down on the important factors (vs trying to evaluate everything, regardless of your own context)
- Model relevant cases
    - Imagine trying to decide between a single payments service, or a service per provider
    - Adding a new provider is simpler with multiple services
    - Maintenance, because of shared code doesn‚Äôt have a clear winner
    - But if you need to introduce a complex workflow using multiple providers (maybe one is a rewards points service), then you need to choose between ‚Äúperformance and data consistency (a single payment service) or sensibility and agility (separate services).‚Äù 410. A or B, simple!
- Definitely simplify, consolidate and focus on outcomes for non-technical stakeholders
- Beware of evangelists. Even if something has always worked for someone, the contexts they‚Äôve worked in may not match the current one. ‚ÄúWe advise architects to avoid evangelising and to try to become the objective arbiter of trade-offs.‚Äù 415 Remember: ‚Äúit‚Äôs not an argument if two sides don‚Äôt exist.‚Äù 415
